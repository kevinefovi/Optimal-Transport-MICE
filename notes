Predicted Mean Matching:
Fill missing data randomly to have a complete dataset. 
Fit a conditional model for column i on the other columns. 
Generate a predicted value for each row, and find set of donors closest to recipient's pred.
value. Randomly pick one
Do this for each column with missing entries.

Over 5 iterations, this will produce imputations that are quite close to the actual values
However, the same predicted values can have different multi variates so clearly 
statistical properties of the data can be lost when matching this way.

OT theory can add the multi variates in the equation when matching, so that the whole 
dataset is taken into account when finding donors. 

---

How OT-PMM helps:
In multimodal / clustered conditionals, different covariate patterns can share the same predicted value. OT looks at the full multivariate predictor space, so donors are matched with recipients that are jointly similar (in terms of dependence structure).

In tight k-NN spaces (when there aren't many donors w.r.t recipients) there could be donor 
overuse. OT smooths this out

Heteroskedasticity - you can add variance in the OT cost so high variance regions are matched with high variance regions 

---

When PMM is optimal and won't benefit much from OT theory:
In low dimensional, near linear homoscedastic relationships with lots of donors 

Given a missing datapoint, fit a conditional model on the other features with observations
(continuous - linear regression)

---

Random Forest used in PMM as the conditional model to calculate predicted values handles 
non linearity and heteroskedasticity well however, the same predicted values can have different covariate patterns. OT could provide better matching 

If the data is near linear, homoscedastic errors and has plenty of donors then OT-PMM won't offer a great deal over PMM (in fact may take more time to perform similarly)